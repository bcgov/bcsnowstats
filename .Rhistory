plot_a <- ggplot(data = all, aes(x = Date, y = swe_mm, colour = station_type)) +
geom_point() +
ggtitle(paste0("ASWE and Manual Timeseries: ", id)) +
ylab("SWE (mm)") +
xlab("Date")
# Plot one against each other
all_xy <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(aswe_swe), !is.na(manual_swe)) %>%
dplyr::mutate(month = as.character(lubridate::month(Date)))
plot_b <- ggplot(data = all_xy, aes(x = manual_swe, y = aswe_swe)) +
geom_point(colour = all_xy$month) +
geom_smooth(method = "lm", se = FALSE) +
ggtitle(paste0("ASWE vs. Manual: ", id)) +
ylab("ASWE SWE (mm)") +
xlab("Manual SWE (mm)")
# Check to see how many years of overlap
# If there is overlap in data, run regression
if (dim(all_xy)[1] > 0) {
# Get regression statistics
linear <- summary(lm(aswe_swe ~ manual_swe, data = all_xy))$coefficients
# get numbers of years of overlap
years_overlap <- max(lubridate::year(all_xy$Date)) - min(lubridate::year(all_xy$Date))
if (years_overlap >= 4) {
missing_aswe <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(est_aswe = linear[1] + linear[2] * manual_swe) %>%
dplyr::mutate(average_diff_percent = mean((aswe_swe - est_aswe)/aswe_swe * 100, na.rm = TRUE)) %>%
dplyr::mutate(id = id,
number_obs = length(na.omit(aswe_swe)),
rmse = sqrt(sum((est_aswe - aswe_swe) ^ 2, na.rm = TRUE) / length(na.omit(aswe_swe)))
)
# Select only the specific columns you need
missing_aswe_s <- missing_aswe %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
} else {
missing_aswe_s <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
}
} else {
missing_aswe_s <- NA
}
# Check to see if data filling created at record of at least 10 years.
years_filled <- missing_aswe_s %>%
dplyr::group_by(survey_period) %>%
dplyr::summarize(number_years = length(swe_out))
# Calculate a normal for the survey period with at least 10 years of data
years_filled_10 <- years_filled %>%
dplyr::full_join(missing_aswe_s) %>%
#filter for the number of years > 10
dplyr::filter(number_years >= 10) %>%
# filter by the normal range
dplyr::mutate(wr = bcsnowdata::wtr_yr(Date)) %>%
dplyr::filter(wr <= normal_max, wr >= normal_min) %>% # Filter by the normal dates that you specify
dplyr::group_by(survey_period) %>%
dplyr::filter(!is.na(swe_out))
# Calculate the normal statistics for each day of the year
df_normals <- do.call(data.frame,
list(dplyr::summarise(years_filled_10, normal_minimum = min(swe_out, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_swe_mean = mean(swe_out, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q5 = quantile(swe_out, 0.05, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q10 = quantile(swe_out, 0.1, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q25 = quantile(swe_out, 0.25, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q50 = quantile(swe_out, 0.5, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q75 = quantile(swe_out, 0.75, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q90 = quantile(swe_out, 0.90, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_maximum = max(swe_out, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::select(-survey_period.1, -survey_period.2, -survey_period.3, -survey_period.4, -survey_period.5, -survey_period.6, -survey_period.7, -survey_period.8) %>%
#dplyr::mutate(Data_Range_normal = (paste0(round(normal_minimum, digits = 0), ' to ', round(normal_maximum, digits = 0)))) %>%
dplyr::mutate(data_range_normal = (paste0(min(lubridate::year(years_filled_10$Date), na.rm = TRUE), " to ", max(lubridate::year(years_filled_10$Date), na.rm = TRUE)))) #%>%
#dplyr::mutate(normal_datarange_estimated = unique(all_swe$numberofyears_estimated_80, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_estimated_80, na.rm = TRUE))]) %>%
#dplyr::mutate(normal_datarange_raw = unique(all_swe$numberofyears_80_raw, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_80_raw, na.rm = TRUE))])
# get the day of the max and min!! Use only 'real', non estimated data
min_date <- years_filled_10 %>%
dplyr::group_by(survey_period) %>%
dplyr::slice(which.min(swe_out)) %>%
dplyr::select(Date, survey_period) %>%
dplyr::rename(date_min_normal_utc = Date)
max_date <- years_filled_10 %>%
dplyr::group_by(survey_period) %>%
dplyr::slice(which.max(swe_out)) %>%
dplyr::select(Date, survey_period) %>%
dplyr::rename(date_max_normal_utc = Date)
dates <- dplyr::full_join(min_date, max_date)
df_normals_out <- dplyr::full_join(df_normals, dates)
} else {
df_normals_out <- NA
}
}
normal_max
normal_min
id
df_normals_out <- manual_2aswe(id = station, normal_max, normal_min)
View(df_normals_out)
rm(list = ls())
library(bcsnowdata)
library(bcsnowstats)
library(dplyr)
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
id_test = bcsnowdata::snow_auto_location()$LOCATION_ID[10]
time_start <- Sys.time()
normals_1B01P  <- SWE_normals(data = "1C40P",
normal_max = 2020,
normal_min = 1991,
force = TRUE)
time_norm <- time_start - Sys.time()
View(normals_1B01P)
data = "1C40P"
normal_max = 2020
normal_min = 1991
force = TRUE
aswe <- bcsnowdata::snow_auto_location()$LOCATION_ID
manual <- bcsnowdata::snow_manual_location()$LOCATION_ID
# if the user input data as a station name (i.e., the function is being used as a stand alone function), get the data for the station
if (all(data %in% aswe)) {
data_norm <- bcsnowdata::get_aswe_databc(
station_id = data,
get_year = "All",
parameter = "swe",
timestep = "daily") %>%
dplyr::rename("values_stats" = value)
id <- data
} else if (all(data %in% manual)) {
data_norm <- bcsnowdata::get_manual_swe(
station_id = data,
get_year = "All",
survey_period = "All")
id <- data
} else {
data_norm <- data
if ("value" %in% colnames(data_norm)) {
data_norm <- data_norm %>%
dplyr::rename("values_stats" = value)
}
id <- unique(data_norm$id)
}
if (dim(data_norm)[1] == 0) {
df_normals_out <- data.frame(station_id = character())
} else if (any(id %in% aswe)) { # Check to see whether the station is a manual or automated station
#data_id <- "value"
# filter data for ASWE sites
data_swe <- data_norm %>%
dplyr::filter(id %in% aswe)
# Use the aswe_normal() function to fill in data (if appropriate) and calculate normals (if there is sufficient data)
df_normals_aswe <- aswe_normal(df = data_swe, normal_max, normal_min, data_id = "values_stats", force = force)
# If the site is manual site
} else if (any(id %in% manual)) {
data_id <- "swe_mm"
# filter data for manual sites
data_man <- data_norm %>%
dplyr::filter(id %in% manual)
df_normals_man <- manual_normal_prep(data = data_man, normal_max = normal_max, normal_min = normal_min, data_id = data_id, force)
} else if (id %in% snow_basins()) {
# if you are trying to simply get the normal for the entire basin, take the average across the data
df_normals_basin <- basin_normal(data = data_norm, normal_max = normal_max, normal_min = normal_min)
}
aswe <- bcsnowdata::snow_auto_location()$LOCATION_ID
manual <- bcsnowdata::snow_manual_location()$LOCATION_ID
all(data %in% aswe)
# if the user input data as a station name (i.e., the function is being used as a stand alone function), get the data for the station
if (all(data %in% aswe)) {
data_norm <- bcsnowdata::get_aswe_databc(
station_id = data,
get_year = "All",
parameter = "swe",
timestep = "daily") %>%
dplyr::rename("values_stats" = value)
id <- data
} else if (all(data %in% manual)) {
data_norm <- bcsnowdata::get_manual_swe(
station_id = data,
get_year = "All",
survey_period = "All")
id <- data
} else {
data_norm <- data
if ("value" %in% colnames(data_norm)) {
data_norm <- data_norm %>%
dplyr::rename("values_stats" = value)
}
id <- unique(data_norm$id)
}
dim(data_norm)[1] == 0
any(id %in% aswe)
# filter data for ASWE sites
data_swe <- data_norm %>%
dplyr::filter(id %in% aswe)
df = data_swe
data_id = "values_stats"
data_dir <- function() {
if (R.Version()$major >= 4) {
getOption("bcsnowstats.data_dir", default = tools::R_user_dir("bcsnowstats", "cache"))
} else {
getOption("bcsnowstats.data_dir", default = rappdirs::user_cache_dir("bcsnowstats"))
}
}
show_cached_files <- function() {
file.path(list.files(data_dir(), full.names = TRUE))
}
check_write_to_data_dir <- function(dir, ask) {
if (ask) {
ans <- gtools::ask(paste("bcsnowstats would like to store this layer in the directory:",
dir, "Is that okay?", sep = "\n"))
if (!(ans %in% c("Yes", "YES", "yes", "y"))) stop("Exiting...", call. = FALSE)
}
if (!dir.exists(dir)) {
message("Creating directory to hold bcsnowstats data at ", dir)
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
} else {
message("Saving to bcsnowstats data directory at ", dir)
}
}
# Check to ensure that the ASWE archived data has been cached on the user's computer and is up to date
fname <- paste0(unique(df$parameter), "_norm_archive.rds")
dir <- data_dir()
fpath <- file.path(dir, fname)
any(!file.exists(fpath)) | force
# Check that the directory exists
check_write_to_data_dir(dir, ask)
ask = FALSE
# Check that the directory exists
check_write_to_data_dir(dir, ask)
data = df
# Put data into right format using the data_massage function
data_m <- data_massage(data)
if ("swe_mean" %in% colnames(data_m)) {
data_id <- "swe_mean" # reassign the data_ID value
}
# Filter the data by the normal span that you specify
df_normal_time <- data_m %>%
dplyr::filter(wr <= normal_max, wr >= normal_min) %>% # Filter by the normal dates that you specify
dplyr::group_by(id, m_d) %>%
dplyr::rename(values_stats = all_of(data_id))
# ++++++++++++++++++++++ thresholds
# Check to see whether there is sufficient data to calculate a normal.
# The WMO recommends only calculating a normal for stations that have 80% of the data available
# Firstly, just show the amount of data available for the normal period
# Number of years with 80% or great of the data available.
# Only count the data between Oct-June - doesn't matter if the snow data is missing in summer - 273 days in snow accumulation/melt season
# Only for ASWE
df_normal_80 <- df_normal_time %>%
dplyr::filter(!is.na(values_stats)) %>% # # filter out missing data
dplyr::ungroup() %>%
dplyr::group_by(id, wr) %>%
dplyr::filter(lubridate::month(as.Date(m_d, format = "%m-%d")) <= 6 || lubridate::month(as.Date(m_d, format = "%m-%d")) >= 10) %>% # get only the snow accumulation and melt season
dplyr::mutate(percent_available = length(values_stats) / length(seq(as.Date("2020-10-01"), as.Date("2021-06-30"), by = "day")) * 100) %>%
dplyr::select(id, wr, percent_available) %>%
unique() %>%
dplyr::filter(percent_available >= 80) # filter by the 80% WMO threshold
# Get the number of years within the normal range with >= 80% data coverage within a specific year
ny_80 <- df_normal_80 %>%
dplyr::group_by(id) %>%
dplyr::summarize(numberofyears_80_raw = n())
# Add the number of years with 80% of data to the dataframe
df_nt <- df_normal_time %>%
dplyr::full_join(ny_80) %>%
dplyr::mutate(numberofyears_80_raw = ifelse(is.na(numberofyears_80_raw), 0, numberofyears_80_raw))
unique(data_m$id)
View(df_nt)
station
station = unique(data_m$id)
numberofyears_80 <- df_nt %>%
ungroup() %>%
dplyr::filter(id %in% station) %>%
dplyr::select(numberofyears_80_raw) %>%
unique()
df_normal_time <- df_nt %>%
dplyr::filter(id %in% station)
dfn_80 <- df_normal_80 %>%
dplyr::filter(id %in% station)
dim(numberofyears_80)[1] == 0
if (dim(numberofyears_80)[1] == 0) {
numberofyears_80_raw <- 0
} else {
numberofyears_80_raw <- numberofyears_80$numberofyears_80_raw
}
numberofyears_80_raw < 10
data_0t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
id = station
id
normal_max
normal_min
substring(unique(id), 1, 4) %in% bcsnowdata::snow_manual_location()$LOCATION_ID
manual_id <- substring(unique(id), 1, 4)
# get manual station data
manual <- bcsnowdata::get_manual_swe(station_id = manual_id)
manual_daily <- manual %>%
dplyr::select(date_utc, swe_mm, survey_period) %>%
dplyr::rename(Date = date_utc) %>%
dplyr::mutate(station_type = "manual")
# get the first and last year of manual data
man_d_min <- lubridate::year(min(manual_daily$Date))
man_d_max <- lubridate::year(max(manual_daily$Date))
man_years <- man_d_max - man_d_min
# Get automated station data
aswe_daily <- bcsnowdata::get_aswe_databc(station_id = id,
parameter = "swe",
timestep = "daily") %>%
dplyr::mutate(Date = as.Date(date_utc)) %>%
dplyr::rename(swe_mm = value) %>%
dplyr::mutate(station_type = "aswe")
# get the first and last year of data
aswe_d_min <- lubridate::year(min(aswe_daily$Date))
aswe_d_max <- lubridate::year(max(aswe_daily$Date))
aswe_d_min
aswe_d_max
# Number of years of data
aswe_years <- aswe_d_max - aswe_d_min
aswe_years
all <- dplyr::full_join(manual_daily, aswe_daily) %>%
dplyr::select(Date, swe_mm, station_type)
# Plot the two together as time series
plot_a <- ggplot(data = all, aes(x = Date, y = swe_mm, colour = station_type)) +
geom_point() +
ggtitle(paste0("ASWE and Manual Timeseries: ", id)) +
ylab("SWE (mm)") +
xlab("Date")
library(ggplot2)
# Plot the two together as time series
plot_a <- ggplot(data = all, aes(x = Date, y = swe_mm, colour = station_type)) +
geom_point() +
ggtitle(paste0("ASWE and Manual Timeseries: ", id)) +
ylab("SWE (mm)") +
xlab("Date")
plot_a
all_xy <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(aswe_swe), !is.na(manual_swe)) %>%
dplyr::mutate(month = as.character(lubridate::month(Date)))
all_xy
all_xy
plot_b <- ggplot(data = all_xy, aes(x = manual_swe, y = aswe_swe)) +
geom_point(colour = all_xy$month) +
geom_smooth(method = "lm", se = FALSE) +
ggtitle(paste0("ASWE vs. Manual: ", id)) +
ylab("ASWE SWE (mm)") +
xlab("Manual SWE (mm)")
plot_b
manual_daily
id
View(aswe_daily)
df_nt
numberofyears_80 <- df_nt %>%
ungroup() %>%
dplyr::filter(id %in% station) %>%
dplyr::select(numberofyears_80_raw) %>%
unique()
df_normal_time <- df_nt %>%
dplyr::filter(id %in% station)
dfn_80 <- df_normal_80 %>%
dplyr::filter(id %in% station)
if (dim(numberofyears_80)[1] == 0) {
numberofyears_80_raw <- 0
} else {
numberofyears_80_raw <- numberofyears_80$numberofyears_80_raw
}
numberofyears_80_raw
numberofyears_80_raw < 10
View(all_xy)
manual_daily
View(manual_daily)
manual_id
manual_id <- substring(unique(id), 1, 4)
# get manual station data
manual <- bcsnowdata::get_manual_swe(station_id = manual_id)
manual_daily <- manual %>%
dplyr::select(date_utc, swe_mm, survey_period) %>%
dplyr::rename(Date = date_utc) %>%
dplyr::mutate(station_type = "manual")
# get the first and last year of manual data
man_d_min <- lubridate::year(min(manual_daily$Date))
man_d_max <- lubridate::year(max(manual_daily$Date))
man_years <- man_d_max - man_d_min
man_years
# Get automated station data
aswe_daily <- bcsnowdata::get_aswe_databc(station_id = id,
parameter = "swe",
timestep = "daily") %>%
dplyr::mutate(Date = as.Date(date_utc)) %>%
dplyr::rename(swe_mm = value) %>%
dplyr::mutate(station_type = "aswe")
# get the first and last year of data
aswe_d_min <- lubridate::year(min(aswe_daily$Date))
aswe_d_max <- lubridate::year(max(aswe_daily$Date))
# Number of years of data
aswe_years <- aswe_d_max - aswe_d_min
aswe_years
id
View(aswe_daily)
lubridate::year(min(aswe_daily$Date))
View(aswe_daily)
aswe_daily$Date
min(aswe_daily$Date)
max(aswe_daily$Date)
aswe_daily <- bcsnowdata::get_aswe_databc(station_id = id,
parameter = "swe",
timestep = "daily") %>%
dplyr::mutate(Date = as.Date(date_utc)) %>%
dplyr::rename(swe_mm = value) %>%
dplyr::mutate(station_type = "aswe") %>%
dplyr::arrange(Date)
View(aswe_daily)
View(all_xy)
dim(all_xy)[1] > 0
# Get regression statistics
linear <- summary(lm(aswe_swe ~ manual_swe, data = all_xy))$coefficients
# get numbers of years of overlap
years_overlap <- max(lubridate::year(all_xy$Date)) - min(lubridate::year(all_xy$Date))
years_overlap
if (years_overlap >= 4) {
missing_aswe <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(est_aswe = linear[1] + linear[2] * manual_swe) %>%
dplyr::mutate(average_diff_percent = mean((aswe_swe - est_aswe)/aswe_swe * 100, na.rm = TRUE)) %>%
dplyr::mutate(id = id,
number_obs = length(na.omit(aswe_swe)),
rmse = sqrt(sum((est_aswe - aswe_swe) ^ 2, na.rm = TRUE) / length(na.omit(aswe_swe)))
)
# Select only the specific columns you need
missing_aswe_s <- missing_aswe %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
} else {
missing_aswe_s <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
}
View(missing_aswe_s)
# Check to see how many years of overlap
# If there is overlap in data, run regression
if (dim(all_xy)[1] > 0) {
# Get regression statistics
linear <- summary(lm(aswe_swe ~ manual_swe, data = all_xy))$coefficients
# get numbers of years of overlap
years_overlap <- max(lubridate::year(all_xy$Date)) - min(lubridate::year(all_xy$Date))
if (years_overlap >= 4) {
missing_aswe <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(est_aswe = linear[1] + linear[2] * manual_swe) %>%
dplyr::mutate(average_diff_percent = mean((aswe_swe - est_aswe)/aswe_swe * 100, na.rm = TRUE)) %>%
dplyr::mutate(id = id,
number_obs = length(na.omit(aswe_swe)),
rmse = sqrt(sum((est_aswe - aswe_swe) ^ 2, na.rm = TRUE) / length(na.omit(aswe_swe)))
)
# Select only the specific columns you need
missing_aswe_s <- missing_aswe %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
} else {
missing_aswe_s <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
}
} else {
missing_aswe_s <- NA
}
# Check to see if data filling created at record of at least 10 years.
years_filled <- missing_aswe_s %>%
dplyr::group_by(survey_period) %>%
dplyr::summarize(number_years = length(swe_out))
years_filled
