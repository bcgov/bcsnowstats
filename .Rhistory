fr_buffer <- sf::st_buffer(location_station, dist = 1e5)
# Filter for those sites within a 100 km buffer
ASWE_100km <- sf::st_filter(location_all, fr_buffer)
# If there are ASWE sites within a 100 km radius, the, proceed with the normal ratio method to backfill missing data
if (length(unique(ASWE_100km$LOCATION_ID)) > 0) {
############## Get the weight of each station
# Get the data for the first station
stations_adj <- unique(ASWE_100km$LOCATION_ID)
# use function to return data estimated from normal ratio method using stations within 100 km of the station of interest
all_swe <- aswe_normalratio(data_soi, stations_adj, data_id, normal_max, normal_min)
} else {
# If there are no stations within a 100 km radius and 20-10 years of data, then do not calculate a normal.
all_swe <- data_soi %>%
dplyr::arrange(date_utc) %>%
dplyr::mutate(swe_fornormal = values_stats)  # make a new column that clearly shows the data to use for normal calculation. If there is 20-10 years of data, and no nearby stations to estimate data, no normal calculated
}
length(unique(ASWE_100km$LOCATION_ID)) > 0
############## Get the weight of each station
# Get the data for the first station
stations_adj <- unique(ASWE_100km$LOCATION_ID)
stations_adj
# use function to return data estimated from normal ratio method using stations within 100 km of the station of interest
all_swe <- aswe_normalratio(data_soi, stations_adj, data_id, normal_max, normal_min)
data_soi
unique(data_soi$id) %in% bcsnowdata::snow_auto_location()$LOCATION_ID
# Was the site converted from a manual site to a ASWE site? Get the name without the P (P shows that the site is ASWE)
station_id_manual <- substring(unique(data_soi$id), 1, 4)
# ==================
# Fill in any missing data with data interpolated from stations within 100km of the station using a normal ratio method
# Are there stations within 100 km?
# First, get the location of the station you are looking at
location_station <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(LOCATION_ID %in% unique(data_soi$id))
location_station <- sf::st_as_sf(location_station)
# All other sites within the vicinity
location_all <- sf::st_as_sf(bcsnowdata::snow_auto_location()) %>%
dplyr::filter(!(LOCATION_ID %in% unique(data_soi$id)))
# 100 km buffer around the site
fr_buffer <- sf::st_buffer(location_station, dist = 1e5)
# Filter for those sites within a 100 km buffer
ASWE_100km <- sf::st_filter(location_all, fr_buffer)
# If there are ASWE sites within a 100 km radius, the, proceed with the normal ratio method to backfill missing data
if (length(unique(ASWE_100km$LOCATION_ID)) > 0) {
############## Get the weight of each station
# Get the data for the first station
stations_adj <- unique(ASWE_100km$LOCATION_ID)
# use function to return data estimated from normal ratio method using stations within 100 km of the station of interest
all_swe <- aswe_normalratio(data_soi, stations_adj, data_id, normal_max, normal_min)
} else {
# If there are no stations within a 100 km radius and 20-10 years of data, then do not calculate a normal.
all_swe <- data_soi %>%
dplyr::arrange(date_utc) %>%
dplyr::mutate(swe_fornormal = values_stats)  # make a new column that clearly shows the data to use for normal calculation. If there is 20-10 years of data, and no nearby stations to estimate data, no normal calculated
}
# use function to return data estimated from normal ratio method using stations within 100 km of the station of interest
all_swe <- aswe_normalratio(data_soi, stations_adj, data_id, normal_max, normal_min)
install.packages(c("BiocManager", "caret", "checkmate", "Hmisc", "igraph", "MASS", "shadowtext"))
rm(list = ls())
library(bcsnowdata)
library(bcsnowstats)
library(dplyr)
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
drive = "\\\\DRAIN.dmz\\Shared"
drive_G = "\\\\Backhoe\\s63101\\Watershare\\rfc"
drive_Q = "\\\\question.bcgov\\envwwwt\\rfc"
drive_R = "\\\\answer.bcgov\\envwww\\rfc"
ASWE_sites_active
normals_all <- SWE_normals(data = ASWE_sites_active[26],
normal_max = 2020,
normal_min = 1991,
force = TRUE)
data = ASWE_sites_active[26]
normal_max = 2020
normal_min = 1991
force = TRUE
aswe <- bcsnowdata::snow_auto_location()$LOCATION_ID
manual <- bcsnowdata::snow_manual_location()$LOCATION_ID
# if the user input data as a station name (i.e., the function is being used as a stand alone function), get the data for the station
if (all(data %in% aswe)) {
data_norm <- bcsnowdata::get_aswe_databc(
station_id = data,
get_year = "All",
parameter = "swe",
timestep = "daily") %>%
dplyr::rename("values_stats" = value)
id <- data
} else if (all(data %in% manual)) {
data_norm <- bcsnowdata::get_manual_swe(
station_id = data,
get_year = "All",
survey_period = "All")
id <- data
} else {
data_norm <- data
if ("value" %in% colnames(data_norm)) {
data_norm <- data_norm %>%
dplyr::rename("values_stats" = value)
}
id <- unique(data_norm$id)
}
dim(data_norm)[1] == 0
any(id %in% aswe)
# filter data for ASWE sites
data_swe <- data_norm %>%
dplyr::filter(id %in% aswe)
df = data_swe
data_id = "values_stats"
data_dir <- function() {
if (R.Version()$major >= 4) {
getOption("bcsnowstats.data_dir", default = tools::R_user_dir("bcsnowstats", "cache"))
} else {
getOption("bcsnowstats.data_dir", default = rappdirs::user_cache_dir("bcsnowstats"))
}
}
show_cached_files <- function() {
file.path(list.files(data_dir(), full.names = TRUE))
}
check_write_to_data_dir <- function(dir, ask) {
if (ask) {
ans <- gtools::ask(paste("bcsnowstats would like to store this layer in the directory:",
dir, "Is that okay?", sep = "\n"))
if (!(ans %in% c("Yes", "YES", "yes", "y"))) stop("Exiting...", call. = FALSE)
}
if (!dir.exists(dir)) {
message("Creating directory to hold bcsnowstats data at ", dir)
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
} else {
message("Saving to bcsnowstats data directory at ", dir)
}
}
# Check to ensure that the ASWE archived data has been cached on the user's computer and is up to date
fname <- paste0(unique(df$parameter), "_norm_archive.rds")
dir <- data_dir()
fpath <- file.path(dir, fname)
any(!file.exists(fpath)) | force
# Check that the directory exists
check_write_to_data_dir(dir, ask)
ask = FALSE
# Check that the directory exists
check_write_to_data_dir(dir, ask)
data = df
data
# Put data into right format using the data_massage function
data_m <- data_massage(data)
if ("swe_mean" %in% colnames(data_m)) {
data_id <- "swe_mean" # reassign the data_ID value
}
# Filter the data by the normal span that you specify
df_normal_time <- data_m %>%
dplyr::filter(wr <= normal_max, wr >= normal_min) %>% # Filter by the normal dates that you specify
dplyr::group_by(id, m_d) %>%
dplyr::rename(values_stats = all_of(data_id))
# ++++++++++++++++++++++ thresholds
# Check to see whether there is sufficient data to calculate a normal.
# The WMO recommends only calculating a normal for stations that have 80% of the data available
# Firstly, just show the amount of data available for the normal period
# Number of years with 80% or great of the data available.
# Only count the data between Oct-June - doesn't matter if the snow data is missing in summer - 273 days in snow accumulation/melt season
# Only for ASWE
df_normal_80 <- df_normal_time %>%
dplyr::filter(!is.na(values_stats)) %>% # # filter out missing data
dplyr::ungroup() %>%
dplyr::group_by(id, wr) %>%
dplyr::filter(lubridate::month(as.Date(m_d, format = "%m-%d")) <= 6 || lubridate::month(as.Date(m_d, format = "%m-%d")) >= 10) %>% # get only the snow accumulation and melt season
dplyr::mutate(percent_available = length(values_stats) / length(seq(as.Date("2020-10-01"), as.Date("2021-06-30"), by = "day")) * 100) %>%
dplyr::select(id, wr, percent_available) %>%
unique() %>%
dplyr::filter(percent_available >= 80) # filter by the 80% WMO threshold
# Get the number of years within the normal range with >= 80% data coverage within a specific year
ny_80 <- df_normal_80 %>%
dplyr::group_by(id) %>%
dplyr::summarize(numberofyears_80_raw = n())
# Add the number of years with 80% of data to the dataframe
df_nt <- df_normal_time %>%
dplyr::full_join(ny_80) %>%
dplyr::mutate(numberofyears_80_raw = ifelse(is.na(numberofyears_80_raw), 0, numberofyears_80_raw))
normals <- lapply(unique(data_m$id),
calc_norm,
df_nt,
df_normal_80, normal_max = normal_max, normal_min = normal_min)
station = unique(data_m$id)
station
numberofyears_80 <- df_nt %>%
ungroup() %>%
dplyr::filter(id %in% station) %>%
dplyr::select(numberofyears_80_raw) %>%
unique()
df_normal_time <- df_nt %>%
dplyr::filter(id %in% station)
dfn_80 <- df_normal_80 %>%
dplyr::filter(id %in% station)
if (dim(numberofyears_80)[1] == 0) {
numberofyears_80_raw <- 0
} else {
numberofyears_80_raw <- numberofyears_80$numberofyears_80_raw
}
numberofyears_80_raw
# =============================
# Fill in data depending on how many years of data there are available
# Is there less than 10 years of data?
if (numberofyears_80_raw < 10) {
data_0t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
# ++++++++++++++++++++++++++++++++++++++++++++++
# Use function to check to see if there is manual site to extend data.
# For now, do not calculate a normal
# Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columms
all_swe <- data_0t10 %>%
dplyr::filter(wr %in% dfn_80$wr) %>%
dplyr::mutate(numberofyears_estimated_80 = numberofyears_80_raw) %>%
dplyr::mutate(swe_fornormal = values_stats)
}
numberofyears_80_raw >= 10 && numberofyears_80_raw < 20
data_20t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
data_soi = data_20t10
unique(data_soi$id) %in% bcsnowdata::snow_auto_location()$LOCATION_ID
# Was the site converted from a manual site to a ASWE site? Get the name without the P (P shows that the site is ASWE)
station_id_manual <- substring(unique(data_soi$id), 1, 4)
# ==================
# Fill in any missing data with data interpolated from stations within 100km of the station using a normal ratio method
# Are there stations within 100 km?
# First, get the location of the station you are looking at
location_station <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(LOCATION_ID %in% unique(data_soi$id))
location_station <- sf::st_as_sf(location_station)
# All other sites within the vicinity
location_all <- sf::st_as_sf(bcsnowdata::snow_auto_location()) %>%
dplyr::filter(!(LOCATION_ID %in% unique(data_soi$id)))
# 100 km buffer around the site
fr_buffer <- sf::st_buffer(location_station, dist = 1e5)
# Filter for those sites within a 100 km buffer
ASWE_100km <- sf::st_filter(location_all, fr_buffer)
length(unique(ASWE_100km$LOCATION_ID)) > 0
############## Get the weight of each station
# Get the data for the first station
stations_adj <- unique(ASWE_100km$LOCATION_ID)
# If there are ASWE sites within a 100 km radius, the, proceed with the normal ratio method to backfill missing data
if (length(unique(ASWE_100km$LOCATION_ID)) > 0) {
############## Get the weight of each station
# Get the data for the first station
stations_adj <- unique(ASWE_100km$LOCATION_ID)
# use function to return data estimated from normal ratio method using stations within 100 km of the station of interest
all_swe <- aswe_normalratio(data_soi, stations_adj, data_id, normal_max, normal_min)
} else {
# If there are no stations within a 100 km radius and 20-10 years of data, then do not calculate a normal.
all_swe <- data_soi %>%
dplyr::arrange(date_utc) %>%
dplyr::mutate(swe_fornormal = values_stats)  # make a new column that clearly shows the data to use for normal calculation. If there is 20-10 years of data, and no nearby stations to estimate data, no normal calculated
}
data_soi
# Format the data from the station of interest  - interpolate for missing data using linear interpolation
data_soi <- data_soi %>%
dplyr::ungroup() %>%
dplyr::mutate(swe_interp = zoo::na.approx(values_stats, na.rm = F, maxgap = 21)) %>%
dplyr::group_by(m_d)
# Take the daily mean
data_soi_m <- do.call(data.frame,
list(dplyr::summarise(data_soi, mean_swe_day = mean(values_stats, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::mutate(date = as.Date(paste0("2020-", m_d))) %>%
dplyr::mutate(mean_swe_day_7 = zoo::rollmean(mean_swe_day, k = 7, na.pad = TRUE, align = c("center"))) %>% # Apply 7 day smoothing to data
dplyr::mutate(mean_swe_day_7 = ifelse(is.na(mean_swe_day_7), mean_swe_day, mean_swe_day_7)) %>% # Get rid of leading NA values
dplyr::mutate(id = unique(data_soi$id))
# Fill any missing data using interpolation
data_soi_m$mean_swe_day_7_fill <- zoo::na.approx(data_soi_m$mean_swe_day_7, na.rm = T, maxgap = 7) # Fill any gaps with linear interpolation
# ------------------------------------------------------
# Calculate the estimated SWE using the ratio normal method (for mean SWE for each day)
ratio_all <- lapply(stations_adj, ratio_function,
data_station_oi = data_soi_m,
data_id, normal_max, normal_min)
ratio_all_unfold <- do.call(rbind, ratio_all)
# Unfold the data
if (dim(ratio_all_unfold)[1] > 0 & !(all(is.na(ratio_all_unfold)))) { # Calculated the estimated SWE for the entire dataset available (if there is data available!)
# Unfold the estimated data from the adjacent stations
estimated_unmelted <- ratio_all_unfold %>%
dplyr::filter(!is.na(estimated_swe)) %>%
unique() %>%
tidyr::spread(id, estimated_swe)
if ("NA" %in% colnames(estimated_unmelted)) {
estimated_unmelted <- estimated_unmelted %>%
dplyr::select(-"NA")
}
# If there are multiple stations, take the row mean. If not, use the one station retrieved
estimated_unmelted_mean <- estimated_unmelted %>%
dplyr::mutate(mean_est_swe = rowMeans(dplyr::select(., -date_utc), na.rm = TRUE)) %>%
dplyr::mutate(date_utc = as.Date(date_utc)) #%>%
#dplyr::mutate(est_swe_5 = zoo::rollmean(mean_est_swe, k = 7, na.pad = TRUE, align = c("center")))
# Join the two datasets together and create a column that is the observed data with the estimated filled in
all_swe_ratio <- dplyr::full_join(data_soi, estimated_unmelted_mean %>% dplyr::select(date_utc, mean_est_swe), by = "date_utc") %>%
dplyr::arrange(date_utc) %>%
dplyr::mutate(swe_est = ifelse(is.na(swe_interp), mean_est_swe, swe_interp))  #if there is no interpolated swe value, fill
all_swe_ratio$swe_est_7 <- zoo::rollmean(as.numeric(all_swe_ratio$swe_est), k = 14, na.pad = TRUE, align = c("center")) # not working in pipe?
all_swe_ratio <- all_swe_ratio %>%
dplyr::mutate(swe_fornormal = swe_est_7) %>% # make a new column that clearly shows the data to use for normal calculation
dplyr::mutate(id = unique(data_soi$id, na.rm = TRUE)) %>%
dplyr::mutate(wr = bcsnowdata::wtr_yr(date_utc)) %>%
dplyr::mutate(m_d = format.Date(date_utc, "%m-%d"))
# Plot the estimated dataset versus the observed
#ggplot() +
#   geom_point(data = all_swe_ratio, aes(x = date_utc, y = swe_fornormal), colour = "blue") +
# geom_point(data = all_swe_ratio, aes(x = date_utc, y = values_stats))
} else {
# If there are no stations within a 100 km radius and 20-10 years of data THAT HAVE DATA, then do not calculate a normal.
all_swe_ratio <- data_soi %>%
dplyr::arrange(date_utc) %>%
dplyr::mutate(swe_fornormal = values_stats)
}
dim(ratio_all_unfold)[1] > 0 & !(all(is.na(ratio_all_unfold)))
# Unfold the estimated data from the adjacent stations
estimated_unmelted <- ratio_all_unfold %>%
dplyr::filter(!is.na(estimated_swe)) %>%
unique() %>%
tidyr::spread(id, estimated_swe)
estimated_unmelted <- ratio_all_unfold %>%
dplyr::filter(!is.na(estimated_swe)) %>%
unique()
View(estimated_unmelted)
stations_adj
data_station_oi = data_soi_m
station = "3A28P"
station
# Get the data for an adjacent station using the ad_data function. Will return a dataframe containing daily mean SWE, as well as a timeseries of daily mean SWE values for each julian day filled via linear interpolation and smoothed by 7-day centered rolling mean
ad_data_all <- ad_data(station, normal_max, normal_min, data_id)
ad_data_m <- do.call(rbind, ad_data_all[2])
View(ad_data_m)
all(is.na(ad_data_m))
# If there is no data, assign the data
if (all(is.na(ad_data_m))) {
# Empty dataframe
est_swe <- NA
} else {
#OLD METHOD - ----------------------------------- before you took the mean day
# Calculate the max yearly SWE for the site you are looking at
# meanmax_yearall <-  max(ad_data_m$mean_swe_day_7_fill_soi, na.rm = TRUE)
# Have a test to reject data that looks like an outlier? There are some instances where the whole year is 0 that looks suspect
# Filter years with the outlier data and calculate the mean max yearly SWE
#if (length(boxplot(meanmax_yearall_ad$max_ad, plot=FALSE)$out) > 0) {
# meanmax_year_ad <- meanmax_yearall_ad %>%
#   dplyr::filter(!(max_ad %in% boxplot(meanmax_yearall_ad$max_ad, plot=FALSE)$out)) %>% # filter the outlier years
#   dplyr::ungroup() %>%
#   dplyr::summarize(mean_max = mean(max_ad, na.rm = TRUE))
#} else {
#  meanmax_year_ad <- meanmax_yearall_ad %>%
#    dplyr::ungroup() %>%
#    dplyr::summarize(mean_max = mean(max_ad, na.rm = TRUE))
#}
# Calculate the mean max yearly SWE for the site you are looking at - station of interest
#meanmax_yearall <- data_station_oi %>%
#  dplyr::ungroup() %>%
#  dplyr::group_by(wr) %>%
#  dplyr::filter(!is.na(values_stats)) %>%
#  dplyr::summarise(max_ad = max(values_stats, na.rm = TRUE), .groups = "keep")
# filter for outlier years within your station data prior to calculating
# if (length(boxplot(meanmax_yearall$max_ad, plot=FALSE)$out) > 0) {
#  meanmax_year <- meanmax_yearall %>%
#    dplyr::filter(!(max_ad %in% (boxplot(meanmax_yearall$max_ad, plot=FALSE)$out))) %>% # filter the outlier years
#    dplyr::ungroup() %>%
#    dplyr::summarize(mean_max = mean(max_ad, na.rm = TRUE))
#} else {
#  meanmax_year <- meanmax_yearall %>%
#    dplyr::ungroup() %>%
#    dplyr::summarize(mean_max = mean(max_ad, na.rm = TRUE))
#}
# Calculate the ratio between the two - station of interest / station you are using to fill in data
# ratio <- data.frame(ratio = ifelse(!is.na(meanmax_year_ad$mean_max),
#                  meanmax_year$mean_max / meanmax_year_ad$mean_max, # store with Id of the station you are using to fill in data
#                  NA)) %>%
#    dplyr::mutate(adj_station_id = unique(ad_st$station_id))
#  colname_es <- paste0("estswe_", station)
# Calculate the ratio * SWE for this station
#  est_SWE <- ad_data %>%
#    dplyr::mutate(ratio = ratio$ratio) %>%
#    dplyr::mutate(estimated_swe = values_stats_ad*ratio) %>%
#    dplyr::select(station_id, date_utc, estimated_swe)
#  -----------------------------------
# NEW METHOD - calculate the ratio between the two by each dat
ratio <- dplyr::full_join(data_station_oi, ad_data_m) %>%
dplyr::mutate(ratio = mean_swe_day_7_fill / mean_swe_7_fill_ad) %>%
dplyr::select(m_d, ratio)
# Calculate the estimated SWE using the raw data from the station of interest
col_name <- paste0(station, "_estimatedSWE")
est_swe <- dplyr::full_join(do.call(rbind, ad_data_all[1]), ratio) %>%
dplyr::mutate(estimated_swe = values_stats_ad * ratio) %>%
dplyr::ungroup() %>%
dplyr::select(date_utc, estimated_swe) %>%
dplyr::mutate(date_utc = as.Date(date_utc)) %>%
dplyr::mutate(estimated_swe = as.numeric(estimated_swe)) %>%
dplyr::mutate(id = unique(station))
}
View(est_swe)
ratio <- dplyr::full_join(data_station_oi, ad_data_m)
View(ratio)
ratio <- dplyr::full_join(data_station_oi, ad_data_m) %>%
dplyr::mutate(ratio = mean_swe_day_7_fill / mean_swe_7_fill_ad) %>%
dplyr::select(m_d, ratio)
col_name <- paste0(station, "_estimatedSWE")
ad_data_all[1])
est_swe <- dplyr::full_join(do.call(rbind, ad_data_all[1]), ratio)
View(est_swe)
do.call(rbind, ad_data_all[1])
View(ad_data_all)
station
normal_max
# Retrieve data for the adjacent station
ad_st <- bcsnowdata::get_aswe_databc(station_id = station,
get_year = "All",
parameter = "swe",
timestep = "daily"
)
View(ad_st)
station
rm(list = ls())
library(bcsnowdata)
library(bcsnowstats)
library(dplyr)
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
normals_all <- SWE_normals(data = ASWE_sites_active[26],
normal_max = 2020,
normal_min = 1991,
force = TRUE)
View(normals_all)
normals_all <- SWE_normals(data = ASWE_sites_active[27:30],
normal_max = 2020,
normal_min = 1991,
force = TRUE)
normals_all <- SWE_normals(data = ASWE_sites_active[31:40],
normal_max = 2020,
normal_min = 1991,
force = TRUE)
normals_all <- SWE_normals(data = ASWE_sites_active[41:50],
normal_max = 2020,
normal_min = 1991,
force = TRUE)
normals_all <- SWE_normals(data = ASWE_sites_active,
normal_max = 2020,
normal_min = 1991,
force = TRUE)
bcsnowdata::snow_auto_location()$LOCATION_ID
tims_start2 <- Sys.time()
plot_test <- plot_interactive_aswe(id = bcsnowdata::snow_auto_location()$LOCATION_ID,
save = TRUE,
path = paste0(drive_Q, "/Real-time_Data/ASP_daily_interactive/ASWE/Interactive_plots/"))
time_save <- tims_start2 - Sys.time()
drive = "\\\\DRAIN.dmz\\Shared"
drive_G = "\\\\Backhoe\\s63101\\Watershare\\rfc"
drive_Q = "\\\\question.bcgov\\envwwwt\\rfc"
drive_R = "\\\\answer.bcgov\\envwww\\rfc"
tims_start2 <- Sys.time()
plot_test <- plot_interactive_aswe(id = bcsnowdata::snow_auto_location()$LOCATION_ID,
save = TRUE,
path = paste0(drive_Q, "/Real-time_Data/ASP_daily_interactive/ASWE/Interactive_plots/"))
time_save <- tims_start2 - Sys.time()
rm(list = ls())
library(bcsnowdata)
library(bcsnowstats)
library(dplyr)
drive = "\\\\DRAIN.dmz\\Shared"
drive_G = "\\\\Backhoe\\s63101\\Watershare\\rfc"
drive_Q = "\\\\question.bcgov\\envwwwt\\rfc"
drive_R = "\\\\answer.bcgov\\envwww\\rfc"
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
lapply(snow_basins(),
plot_interactive_basin,
exceptions = NA,
path_basin = paste0(drive_Q, "/Real-time_Data/ASP_daily_interactive/ASWE/Basinaveraged_plots/"),
save = TRUE)
install.packages("plotly")
library(bcsnowstats)
library(bcsnowstats)
rm(list = ls())
library(bcsnowdata)
library(bcsnowstats)
library(dplyr)
ASWE_sites <- bcsnowdata::snow_auto_location() %>%
dplyr::filter(STATUS == "Active")
ASWE_sites_active <- ASWE_sites$LOCATION_ID
id_test = bcsnowdata::snow_auto_location()$LOCATION_ID[10]
tims_start <- Sys.time()
test <- get_snow_stats(station_id = ASWE_sites$LOCATION_ID,
survey_period = "All",
get_year = "2022",
normal_min = 1991,
normal_max = 2020,
force = FALSE)
time_1 <- tims_start - Sys.time()
id_man
id_man <- c("4E01", "4E02",  "4E02A", "4E02B", "4E03")
time_start = Sys.time()
stats_man_west <- bcsnowstats::stats_MSWE(station_id = id_man,
survey_period = "01-Mar",
get_year = "2021",
normal_min = 1991,
normal_max = 2020)
id_man
stats_man_west <- bcsnowstats::stats_MSWE(station_id = id_man,
survey_period = "01-May",
get_year = "2022",
normal_min = 1991,
normal_max = 2020)
bcsnowdata::snow_manual_location()$LOCATION_ID
stats_man_west <- bcsnowstats::stats_MSWE(station_id = bcsnowdata::snow_manual_location()$LOCATION_ID,
survey_period = "01-May",
get_year = "2022",
normal_min = 1991,
normal_max = 2020)
