} else {
missing_aswe_s <- dplyr::full_join(manual_daily %>%
dplyr::rename(manual_swe = swe_mm) %>%
dplyr::select(-station_type),
aswe_daily %>%
dplyr::rename(aswe_swe = swe_mm) %>%
dplyr::select(-station_type)) %>%
dplyr::filter(!is.na(manual_swe)) %>%
dplyr::mutate(data_flag = ifelse(is.na(aswe_swe), "estimated", "raw")) %>%
dplyr::mutate(swe_out = ifelse(is.na(aswe_swe), est_aswe, aswe_swe)) %>%
dplyr::select(Date, survey_period, swe_out, data_flag)
}
# Check to see if data filling created at record of at least 10 years.
years_filled <- missing_aswe_s %>%
dplyr::group_by(survey_period) %>%
dplyr::full_join(missing_aswe_s) %>%
# filter by the normal range
dplyr::mutate(wr = bcsnowdata::wtr_yr(Date)) %>%
dplyr::filter(wr <= normal_max, wr >= normal_min) %>% # Filter by the normal dates that you specify
dplyr::group_by(survey_period) %>%
dplyr::filter(!is.na(swe_out))
# Calculate a normal for the survey period with at least 10 years of data
years_filled_10 <- years_filled %>%
dplyr::group_by(survey_period) %>%
dplyr::summarize(number_years = length(swe_out)) %>%
dplyr::full_join(years_filled) %>%
dplyr::filter(number_years >= 10) %>%
dplyr::group_by(survey_period)
# Calculate the normal statistics for each day of the year
df_normals <- do.call(data.frame,
list(dplyr::summarise(years_filled_10, normal_minimum = min(swe_out, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_swe_mean = mean(swe_out, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q5 = quantile(swe_out, 0.05, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q10 = quantile(swe_out, 0.1, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q25 = quantile(swe_out, 0.25, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q50 = quantile(swe_out, 0.5, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q75 = quantile(swe_out, 0.75, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_Q90 = quantile(swe_out, 0.90, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(years_filled_10, normal_maximum = max(swe_out, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::select(-survey_period.1, -survey_period.2, -survey_period.3, -survey_period.4, -survey_period.5, -survey_period.6, -survey_period.7, -survey_period.8) %>%
#dplyr::mutate(Data_Range_normal = (paste0(round(normal_minimum, digits = 0), ' to ', round(normal_maximum, digits = 0)))) %>%
dplyr::mutate(data_range_normal = (paste0(normal_min, " to ", normal_max))) %>%
dplyr::mutate(normal_datarange_estimated = paste0(min(lubridate::year(years_filled_10$Date), na.rm = TRUE), " to ", max(lubridate::year(years_filled_10$Date), na.rm = TRUE))) %>%
dplyr::mutate(normal_datarange_raw = paste0(aswe_d_min, " to ", aswe_d_max)) %>%
dplyr::full_join(years_filled_10 %>% dplyr::select(survey_period, number_years)) %>%
dplyr::rename(numberofyears_estimated_80 = number_years)
# get the day of the max and min!! Use only 'real', non estimated data
min_date <- years_filled_10 %>%
dplyr::group_by(survey_period) %>%
dplyr::slice(which.min(swe_out)) %>%
dplyr::select(Date, survey_period) %>%
dplyr::rename(date_min_normal_utc = Date)
max_date <- years_filled_10 %>%
dplyr::group_by(survey_period) %>%
dplyr::slice(which.max(swe_out)) %>%
dplyr::select(Date, survey_period) %>%
dplyr::rename(date_max_normal_utc = Date)
dates <- dplyr::full_join(min_date, max_date)
df_normals_out <- dplyr::full_join(df_normals, dates) %>%
dplyr::mutate(data_flag = "<10 years data; filled from manual data") %>%
dplyr::mutate(m_d = format(survey_period, format = "%m-%d"))
} else {
df_normals_out <- NA
}
} else {
df_normals_out <- NA
}
# ++++++++++++++++++++++++++++++++++++++++++++++
# Use function to calculate the normal if the station was converted from manual to aswe
df_normals <- manual_2aswe(id = station, normal_max, normal_min)
df_normals
is.null(dim(df_normals)[1])
data_0t10 <- df_normal_time %>% # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
dplyr::mutate(survey_period = format(date_utc, format = "%d-%b"))
# =============================
# Fill in data depending on how many years of data there are available
# Is there less than 10 years of data?
if (numberofyears_80_raw < 10) {
data_0t10 <- df_normal_time %>% # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
dplyr::mutate(survey_period = format(date_utc, format = "%d-%b"))
# ++++++++++++++++++++++++++++++++++++++++++++++
# Use function to calculate the normal if the station was converted from manual to aswe
df_normals <- manual_2aswe(id = station, normal_max, normal_min)
# Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columms
if (is.null(dim(df_normals)[1])) {
df_normals_out <- data.frame("id"  = station,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = NA)
} else {
df_normals_out <- df_normals
}
all_swe <- NULL
}
View(df_normals_out)
# Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columms
if (is.null(dim(df_normals)[1])) {
df_normals_out <- data.frame("id"  = station,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = "insufficient data")
} else {
df_normals_out <- df_normals
}
# Does the station have between 10-20 years of data? If so, extend the dataset using 1) manual dataset (if converted), and 2) adjacent stations
if (numberofyears_80_raw >= 10 && numberofyears_80_raw < 20) {
data_20t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
# Fill in missing data with an estimated dataset from either manual dataset (if converted) and/or adjacent stations
all_swe <- snow_datafill(data_soi = data_20t10, data_id, normal_max, normal_min) %>%
dplyr::mutate(data_flag = "10-20 years of data; data filled from adjacent sites")
}
# Does the site have between 20-30 years of data? Don't add in any additional data and jsut calculcate normals from
if (numberofyears_80_raw >= 20 && numberofyears_80_raw <= 30) {
# DON'T Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columns
all_swe <- df_normal_time %>%
#dplyr::filter(wr %in% df_normal_80$wr) %>%
dplyr::mutate(numberofyears_estimated_80 = numberofyears_80$numberofyears_80_raw) %>%
dplyr::mutate(swe_fornormal = values_stats)%>%
dplyr::mutate(data_flag = ">20 years of data; no data filling")
}
# ==============================
# Calculate normals. Only calculate normal if there is sufficient data
if (length(all_swe$numberofyears_estimated_80) > 0 && unique(all_swe$numberofyears_estimated_80) >= 20 && unique(all_swe$numberofyears_estimated_80) <= 30 && numberofyears_80_raw >= 10) {
all_swe_1 <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::filter(!is.na(swe_fornormal))
# Calculate the normal statistics for each day of the year
df_normals <- do.call(data.frame,
list(dplyr::summarise(all_swe_1, normal_minimum = min(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_swe_mean = mean(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q5 = quantile(swe_fornormal, 0.05, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q10 = quantile(swe_fornormal, 0.1, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q25 = quantile(swe_fornormal, 0.25, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q50 = quantile(swe_fornormal, 0.5, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q75 = quantile(swe_fornormal, 0.75, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q90 = quantile(swe_fornormal, 0.90, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_maximum = max(swe_fornormal, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::select(-m_d.1, -m_d.2, -m_d.3, -m_d.4, -m_d.5, -m_d.6, -m_d.7, -m_d.8) %>%
dplyr::select(-id.1, -id.2, -id.3, -id.4, -id.5, -id.6, -id.7, -id.8) %>%
#dplyr::mutate(Data_Range_normal = (paste0(round(normal_minimum, digits = 0), ' to ', round(normal_maximum, digits = 0)))) %>%
dplyr::mutate(data_range_normal = (paste0(min(lubridate::year(all_swe$date_utc), na.rm = TRUE), " to ", max(lubridate::year(all_swe$date_utc), na.rm = TRUE)))) %>%
dplyr::mutate(normal_datarange_estimated = unique(all_swe$numberofyears_estimated_80, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_estimated_80, na.rm = TRUE))]) %>%
dplyr::mutate(normal_datarange_raw = unique(all_swe$numberofyears_80_raw, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_80_raw, na.rm = TRUE))])
# get the day of the max and min!! Use only 'real', non estimated data
min_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.min(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_min_normal_utc = date_utc)
max_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.max(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_max_normal_utc = date_utc)
# append to data
dates <- dplyr::full_join(min_date, max_date, by = c("id", "m_d"))
df_normals_out <- dplyr::full_join(df_normals, dates, by = c("id", "m_d")) %>%
dplyr::mutate(initial_normal_range = paste0(normal_min, " to ", normal_max))
# Smooth all the statistics by the 5 -day average?
# If there is less than 10 years of data available even after trying adjacent sites, return
} else if (numberofyears_80_raw < 10) {
df_normals_out <- df_normals_out
} else {
df_normals_out <- data.frame("id"  = station,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = NA)
}
#' July 2022, Ashlee Jollymore
#' @param station station that you are calculating statistics for
#' @param df_nt data
#' @param df_normal_80 data that reaches the 80% completeness threshold
#' @param normal_min date for the min normal year
#' @param normal_max date of the max normal year
#' @export
#' @keywords internal
#' @examples \dontrun{}
#
calc_norm <- function(station, df_nt, df_normal_80, normal_max, normal_min) {
numberofyears_80 <- df_nt %>%
ungroup() %>%
dplyr::filter(id %in% station) %>%
dplyr::select(numberofyears_80_raw) %>%
unique()
df_normal_time <- df_nt %>%
dplyr::filter(id %in% station)
dfn_80 <- df_normal_80 %>%
dplyr::filter(id %in% station)
if (dim(numberofyears_80)[1] == 0) {
numberofyears_80_raw <- 0
} else {
numberofyears_80_raw <- numberofyears_80$numberofyears_80_raw
}
# =============================
# Fill in data depending on how many years of data there are available
# Is there less than 10 years of data?
if (numberofyears_80_raw < 10) {
data_0t10 <- df_normal_time %>% # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
dplyr::mutate(survey_period = format(date_utc, format = "%d-%b"))
# ++++++++++++++++++++++++++++++++++++++++++++++
# Use function to calculate the normal if the station was converted from manual to aswe
df_normals <- manual_2aswe(id = station, normal_max, normal_min)
# Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columms
if (is.null(dim(df_normals)[1])) {
df_normals_out <- data.frame("id"  = station,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = "insufficient data")
} else {
df_normals_out <- df_normals
}
all_swe <- NULL
}
# Does the station have between 10-20 years of data? If so, extend the dataset using 1) manual dataset (if converted), and 2) adjacent stations
if (numberofyears_80_raw >= 10 && numberofyears_80_raw < 20) {
data_20t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
# Fill in missing data with an estimated dataset from either manual dataset (if converted) and/or adjacent stations
all_swe <- snow_datafill(data_soi = data_20t10, data_id, normal_max, normal_min) %>%
dplyr::mutate(data_flag = "10-20 years of data; data filled from adjacent sites")
}
# Does the site have between 20-30 years of data? Don't add in any additional data and jsut calculcate normals from
if (numberofyears_80_raw >= 20 && numberofyears_80_raw <= 30) {
# DON'T Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columns
all_swe <- df_normal_time %>%
#dplyr::filter(wr %in% df_normal_80$wr) %>%
dplyr::mutate(numberofyears_estimated_80 = numberofyears_80$numberofyears_80_raw) %>%
dplyr::mutate(swe_fornormal = values_stats)%>%
dplyr::mutate(data_flag = ">20 years of data; no data filling")
}
# End of data filling according to thresholds
# ==============================
# Calculate normals. Only calculate normal if there is sufficient data
if (length(all_swe$numberofyears_estimated_80) > 0 && unique(all_swe$numberofyears_estimated_80) >= 20 && unique(all_swe$numberofyears_estimated_80) <= 30 && numberofyears_80_raw >= 10) {
all_swe_1 <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::filter(!is.na(swe_fornormal))
# Calculate the normal statistics for each day of the year
df_normals <- do.call(data.frame,
list(dplyr::summarise(all_swe_1, normal_minimum = min(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_swe_mean = mean(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q5 = quantile(swe_fornormal, 0.05, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q10 = quantile(swe_fornormal, 0.1, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q25 = quantile(swe_fornormal, 0.25, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q50 = quantile(swe_fornormal, 0.5, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q75 = quantile(swe_fornormal, 0.75, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q90 = quantile(swe_fornormal, 0.90, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_maximum = max(swe_fornormal, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::select(-m_d.1, -m_d.2, -m_d.3, -m_d.4, -m_d.5, -m_d.6, -m_d.7, -m_d.8) %>%
dplyr::select(-id.1, -id.2, -id.3, -id.4, -id.5, -id.6, -id.7, -id.8) %>%
#dplyr::mutate(Data_Range_normal = (paste0(round(normal_minimum, digits = 0), ' to ', round(normal_maximum, digits = 0)))) %>%
dplyr::mutate(data_range_normal = (paste0(min(lubridate::year(all_swe$date_utc), na.rm = TRUE), " to ", max(lubridate::year(all_swe$date_utc), na.rm = TRUE)))) %>%
dplyr::mutate(normal_datarange_estimated = unique(all_swe$numberofyears_estimated_80, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_estimated_80, na.rm = TRUE))]) %>%
dplyr::mutate(normal_datarange_raw = unique(all_swe$numberofyears_80_raw, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_80_raw, na.rm = TRUE))])
# get the day of the max and min!! Use only 'real', non estimated data
min_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.min(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_min_normal_utc = date_utc)
max_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.max(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_max_normal_utc = date_utc)
# append to data
dates <- dplyr::full_join(min_date, max_date, by = c("id", "m_d"))
df_normals_out <- dplyr::full_join(df_normals, dates, by = c("id", "m_d")) %>%
dplyr::mutate(initial_normal_range = paste0(normal_min, " to ", normal_max))
# Smooth all the statistics by the 5 -day average?
# If there is less than 10 years of data available even after trying adjacent sites, return
} else if (numberofyears_80_raw < 10) {
df_normals_out <- df_normals_out
} else {
df_normals_out <- data.frame("id"  = station,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = NA)
}
return(df_normals_out)
}
normals <- lapply(unique(data_m$id),
calc_norm,
df_nt = df_nt,
df_normal_80 = df_normal_80, normal_max = normal_max, normal_min = normal_min)
df_normals <- lapply(unique(data_m$id),
calc_norm,
df_nt = df_nt,
df_normal_80 = df_normal_80, normal_max = normal_max, normal_min = normal_min)
df_normals_final <- do.call(plyr::rbind.fill, df_normals) %>%
unique()
unique(data$id)
data
unique(data$id)
#' July 2022, Ashlee Jollymore
#' @param station station that you are calculating statistics for
#' @param df_nt data
#' @param df_normal_80 data that reaches the 80% completeness threshold
#' @param normal_min date for the min normal year
#' @param normal_max date of the max normal year
#' @export
#' @keywords internal
#' @examples \dontrun{}
#
calc_norm <- function(stn_id, df_nt, df_normal_80, normal_max, normal_min) {
numberofyears_80 <- df_nt %>%
ungroup() %>%
dplyr::filter(id %in% stn_id) %>%
dplyr::select(numberofyears_80_raw) %>%
unique()
df_normal_time <- df_nt %>%
dplyr::filter(id %in% stn_id)
dfn_80 <- df_normal_80 %>%
dplyr::filter(id %in% stn_id)
if (dim(numberofyears_80)[1] == 0) {
numberofyears_80_raw <- 0
} else {
numberofyears_80_raw <- numberofyears_80$numberofyears_80_raw
}
# =============================
# Fill in data depending on how many years of data there are available
# Is there less than 10 years of data?
if (numberofyears_80_raw < 10) {
data_0t10 <- df_normal_time %>% # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
dplyr::mutate(survey_period = format(date_utc, format = "%d-%b"))
# ++++++++++++++++++++++++++++++++++++++++++++++
# Use function to calculate the normal if the stn_id was converted from manual to aswe
df_normals <- manual_2aswe(id = stn_id, normal_max, normal_min)
# Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columms
if (is.null(dim(df_normals)[1])) {
df_normals_out <- data.frame("id"  = stn_id,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = "insufficient data")
} else {
df_normals_out <- df_normals
}
all_swe <- NULL
}
# Does the station have between 10-20 years of data? If so, extend the dataset using 1) manual dataset (if converted), and 2) adjacent stations
if (numberofyears_80_raw >= 10 && numberofyears_80_raw < 20) {
data_20t10 <- df_normal_time # Make a new variable to preserve the initial data - years with at least 80% of the data in the snow accumulation period.
# Fill in missing data with an estimated dataset from either manual dataset (if converted) and/or adjacent stations
all_swe <- snow_datafill(data_soi = data_20t10, data_id, normal_max, normal_min) %>%
dplyr::mutate(data_flag = "10-20 years of data; data filled from adjacent sites")
}
# Does the site have between 20-30 years of data? Don't add in any additional data and jsut calculcate normals from
if (numberofyears_80_raw >= 20 && numberofyears_80_raw <= 30) {
# DON'T Filter out the years that have less that 80% of the data within the snow accumulation season; Add in correct columns
all_swe <- df_normal_time %>%
#dplyr::filter(wr %in% df_normal_80$wr) %>%
dplyr::mutate(numberofyears_estimated_80 = numberofyears_80$numberofyears_80_raw) %>%
dplyr::mutate(swe_fornormal = values_stats)%>%
dplyr::mutate(data_flag = ">20 years of data; no data filling")
}
# End of data filling according to thresholds
# ==============================
# Calculate normals. Only calculate normal if there is sufficient data
if (length(all_swe$numberofyears_estimated_80) > 0 && unique(all_swe$numberofyears_estimated_80) >= 20 && unique(all_swe$numberofyears_estimated_80) <= 30 && numberofyears_80_raw >= 10) {
all_swe_1 <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::filter(!is.na(swe_fornormal))
# Calculate the normal statistics for each day of the year
df_normals <- do.call(data.frame,
list(dplyr::summarise(all_swe_1, normal_minimum = min(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_swe_mean = mean(swe_fornormal, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q5 = quantile(swe_fornormal, 0.05, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q10 = quantile(swe_fornormal, 0.1, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q25 = quantile(swe_fornormal, 0.25, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q50 = quantile(swe_fornormal, 0.5, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q75 = quantile(swe_fornormal, 0.75, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_Q90 = quantile(swe_fornormal, 0.90, na.rm = TRUE), .groups = "keep"),
dplyr::summarise(all_swe_1, normal_maximum = max(swe_fornormal, na.rm = TRUE), .groups = "keep"))) %>%
dplyr::select(-m_d.1, -m_d.2, -m_d.3, -m_d.4, -m_d.5, -m_d.6, -m_d.7, -m_d.8) %>%
dplyr::select(-id.1, -id.2, -id.3, -id.4, -id.5, -id.6, -id.7, -id.8) %>%
#dplyr::mutate(Data_Range_normal = (paste0(round(normal_minimum, digits = 0), ' to ', round(normal_maximum, digits = 0)))) %>%
dplyr::mutate(data_range_normal = (paste0(min(lubridate::year(all_swe$date_utc), na.rm = TRUE), " to ", max(lubridate::year(all_swe$date_utc), na.rm = TRUE)))) %>%
dplyr::mutate(normal_datarange_estimated = unique(all_swe$numberofyears_estimated_80, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_estimated_80, na.rm = TRUE))]) %>%
dplyr::mutate(normal_datarange_raw = unique(all_swe$numberofyears_80_raw, na.rm = TRUE)[!is.na(unique(all_swe$numberofyears_80_raw, na.rm = TRUE))])
# get the day of the max and min!! Use only 'real', non estimated data
min_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.min(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_min_normal_utc = date_utc)
max_date <- all_swe %>%
dplyr::group_by(id, m_d) %>%
dplyr::slice(which.max(values_stats)) %>%
dplyr::select(date_utc, id, m_d) %>%
dplyr::rename(date_max_normal_utc = date_utc)
# append to data
dates <- dplyr::full_join(min_date, max_date, by = c("id", "m_d"))
df_normals_out <- dplyr::full_join(df_normals, dates, by = c("id", "m_d")) %>%
dplyr::mutate(initial_normal_range = paste0(normal_min, " to ", normal_max))
# Smooth all the statistics by the 5 -day average?
# If there is less than 10 years of data available even after trying adjacent sites, return
} else if (numberofyears_80_raw < 10) {
df_normals_out <- df_normals_out
} else {
df_normals_out <- data.frame("id"  = stn_id,
"m_d" = NA,
"normal_minimum" = NA,
"normal_swe_mean" = NA,
"normal_Q5" = NA,
"normal_Q10" = NA,
"normal_Q25"  = NA,
"normal_Q50" = NA,
"normal_Q75" = NA,
"normal_Q90" = NA,
"normal_maximum" = NA,
"data_range_normal" = NA,
"initial_normal_range" = paste0(normal_min, " to ", normal_max),
"normal_datarange_estimated" = NA,
"normal_datarange_raw" = NA,
"date_min_normal_utc" = NA,
"date_max_normal_utc"  = NA,
"data_flag" = NA)
}
return(df_normals_out)
}
df_normals <- lapply(unique(data$id),
calc_norm,
df_nt = df_nt,
df_normal_80 = df_normal_80, normal_max = normal_max, normal_min = normal_min)
df_normals_final <- do.call(plyr::rbind.fill, df_normals) %>%
unique()
unique(data$id)
stn_id = id
stn_id
